#!/bin/bash

set -o errexit

test_dir=$(realpath $(dirname $0))
deploy_dir=$(realpath $(dirname $0)/../../deploy)
. ${test_dir}/../functions
set_debug

# Since we've switched to 4 mongo pods as a safe configuration for arbiter
# such a test requires more than 3 kubernetes nodes due to anti-affinity settings

function stop_cluster() {
	local cluster_name=$1
	local max_wait_time=${2:-120}

	local passed_time=0
	local sleep_time=1
	kubectl_bin patch psmdb ${cluster_name} --type json -p='[{"op":"add","path":"/spec/pause","value":true}]'
	set +x
	echo -n 'Waiting for cluster stop'
	until [[ $(kubectl_bin get psmdb ${cluster_name} -o jsonpath='{.status.mongos.ready}') -le 0 ]] \
		&& [[ $(kubectl_bin get deployment ${cluster_name}-mongos -o jsonpath='{.status.replicas}') -le 0 ]] \
		&& [[ $(kubectl_bin get psmdb ${cluster_name} -o jsonpath='{.status.replsets.cfg.ready}') -le 0 ]] \
		&& [[ $(kubectl_bin get psmdb ${cluster_name} -o jsonpath='{.status.replsets.rs0.ready}') -le 0 ]]; do
		echo -n .
		let passed_time="${passed_time}+${sleep_time}"
		sleep ${sleep_time}
		if [[ ${passed_time} -gt ${max_wait_time} ]]; then
			echo "We've been waiting for cluster stop for too long. Exiting..."
			exit 1
		fi
	done
	echo
	set -x
}

function start_cluster() {
	local cluster_name=$1

	kubectl_bin patch psmdb ${cluster_name} --type json -p='[{"op":"add","path":"/spec/pause","value":false}]'
	wait_cluster_consistency ${cluster_name} 42
}

function main() {
	create_infra "$namespace"
	cluster="my-cluster-name"

	desc 'create secrets and start client'
	kubectl_bin apply -f $deploy_dir/secrets.yaml
	kubectl_bin apply -f $conf_dir/client.yml

	desc "create first PSMDB cluster $cluster"
	kubectl_bin apply ${OPERATOR_NS:+-n $OPERATOR_NS} --server-side --force-conflicts -f $deploy_dir/crd.yaml
	if [ -n "$OPERATOR_NS" ]; then
		apply_rbac cw-rbac
		kubectl_bin apply -n ${OPERATOR_NS} -f $deploy_dir/cw-operator.yaml
	else
		apply_rbac rbac
		yq eval '((.. | select(.[] == "DISABLE_TELEMETRY")) |= .value="true")' "$deploy_dir/operator.yaml" \
			| kubectl_bin apply -f -
	fi

	yq eval '.spec.upgradeOptions.versionServiceEndpoint = "https://check-dev.percona.com" |
		.spec.replsets[].affinity.antiAffinityTopologyKey = "none" |
		.spec.replsets[].nonvoting.affinity.antiAffinityTopologyKey = "none" |
		.spec.replsets[].arbiter.affinity.antiAffinityTopologyKey = "none" |
		.spec.sharding.configsvrReplSet.affinity.antiAffinityTopologyKey = "none" |
		.spec.sharding.mongos.affinity.antiAffinityTopologyKey = "none"' $deploy_dir/cr.yaml \
		| kubectl_bin apply -f -

	desc 'check if all 3 Pods started'
	wait_cluster_consistency $cluster 42

	desc 'check if service and statefulset created with expected config'
	compare_kubectl statefulset/$cluster-rs0
	compare_kubectl statefulset/$cluster-cfg

	compare_generation "1" "statefulset" "${cluster}-rs0"
	compare_generation "1" "statefulset" "${cluster}-cfg"
	compare_generation "1" "statefulset" "${cluster}-mongos"
	compare_generation "1" "psmdb" "${cluster}"

	desc 'starting PMM server'
	if [ ! -z "$OPENSHIFT" ]; then
		platform=openshift
		oc create sa pmm-server
		oc adm policy add-scc-to-user privileged -z pmm-server
		oc create rolebinding pmm-psmdb-operator-namespace-only --role percona-server-mongodb-operator --serviceaccount=$namespace:pmm-server
		oc patch role/percona-server-mongodb-operator --type json -p='[{"op":"add","path": "/rules/-","value":{"apiGroups":["security.openshift.io"],"resources":["securitycontextconstraints"],"verbs":["use"],"resourceNames":["privileged"]}}]'
		retry 10 60 helm install monitoring --set imageTag=$IMAGE_PMM_SERVER_TAG --set imageRepo=$IMAGE_PMM_SERVER_REPO --set platform=$platform --set sa=pmm-server --set supresshttp2=false https://percona-charts.storage.googleapis.com/pmm-server-${PMM_SERVER_VER}.tgz
	else
		helm install monitoring --set imageTag=$IMAGE_PMM_SERVER_TAG --set imageRepo=$IMAGE_PMM_SERVER_REPO --set platform=$platform https://percona-charts.storage.googleapis.com/pmm-server-${PMM_SERVER_VER}.tgz
	fi
	sleep 20
	kubectl_bin patch psmdb ${cluster} --type=merge --patch '{
			"spec": {"pmm":{"enabled":true}}
		}'
	sleep 120
	# since psmdb cluster won't work without pmm server running consistency check would be enough
	wait_cluster_consistency $cluster

	kubectl_bin patch psmdb ${cluster} --type=merge --patch '{
			"spec": {"pmm":{"enabled":false}}
		}'
	sleep 120
	helm uninstall monitoring
	wait_cluster_consistency $cluster

	desc 'enabling arbiter'
	kubectl_bin patch psmdb ${cluster} --type json -p='[{"op":"replace","path":"/spec/replsets/0/arbiter/enabled","value":true}]'
	wait_cluster_consistency $cluster
	wait_pod $cluster-rs0-arbiter-0

	desc 'create user'
	run_mongos \
		'db.createUser({user:"myApp",pwd:"myPass",roles:[{db:"myApp",role:"readWrite"}]})' \
		"userAdmin:userAdmin123456@$cluster-mongos.$namespace"
	sleep 2

	desc 'checking write/read'
	run_mongos \
		'use myApp\n db.test.insert({ x: 100500 })' \
		"myApp:myPass@$cluster-mongos.$namespace"
	simple_data_check "${cluster}" 4 1 "-mongos"

	desc 'checking dev version service'
	stop_cluster ${cluster}
	start_cluster ${cluster}
	simple_data_check "${cluster}" 4 1 "-mongos"

	desc "delete cluster $cluster"
	kubectl_bin delete -f $deploy_dir/cr.yaml

	desc 'create secrets'
	cluster="minimal-cluster"
	yq eval '.metadata.name = "'${cluster}'"' $deploy_dir/secrets.yaml | kubectl_bin apply -f -

	yq eval '.spec.upgradeOptions.versionServiceEndpoint = "https://check-dev.percona.com"' $deploy_dir/cr-minimal.yaml | kubectl_bin apply -f -
	desc 'check if all Pods started'
	wait_cluster_consistency "${cluster}"

	desc 'check if service and statefulset created with expected config'
	compare_kubectl statefulset/"${cluster}"-rs0
	compare_kubectl statefulset/"${cluster}"-cfg

	compare_generation "1" "statefulset" "${cluster}-rs0"
	compare_generation "1" "statefulset" "${cluster}-cfg"
	compare_generation "1" "statefulset" "${cluster}-mongos"
	compare_generation "1" "psmdb" "${cluster}"

	desc 'create user'
	run_mongos \
		'db.createUser({user:"myApp",pwd:"myPass",roles:[{db:"myApp",role:"readWrite"}]})' \
		"userAdmin:userAdmin123456@$cluster-mongos.$namespace"
	sleep 2

	desc 'write data, read it'
	run_mongos \
		'use myApp\n db.test.insert({ x: 100500 })' \
		"myApp:myPass@$cluster-mongos.$namespace"
	simple_data_check "${cluster}" 4 1 "-mongos"

	destroy $namespace

	desc 'test passed'
}

main
