#!/bin/bash

set -o errexit

test_dir=$(realpath $(dirname $0))
. ${test_dir}/../functions
set_debug

cluster="some-name-rs0"

setup_cluster() {
	desc 'create secrets and start client'
	kubectl_bin apply \
		-f $conf_dir/secrets.yml

	desc "create first PSMDB cluster $cluster"
	apply_cluster $conf_dir/$cluster.yml

	# check if all 3 Pods started
	wait_for_running "$cluster" 3
	wait_cluster_consistency "${cluster/-rs0/}" 3
}

fail_pod() {
	local init_pod=$(get_operator_pod)
	local restart_count_before=$(kubectl_bin get pod ${OPERATOR_NS:+-n $OPERATOR_NS} ${init_pod} -ojsonpath='{.status.containerStatuses[0].restartCount}')

	yq eval '
		.metadata.name = "chaos-operator-pod-failure" |
		del(.spec.selector.pods.test-namespace) |
		.spec.selector.pods.'$test_namespace'[0] = "'$init_pod'"' $conf_dir/chaos-pod-failure.yml \
		| kubectl apply --namespace $test_namespace -f -
	sleep 10

	desc 'check if operator works fine: scale down from 5 to 3'
	kubectl_bin patch psmdb ${cluster%%-rs0} \
		--type='json' \
		-p='[{"op": "replace", "path": "/spec/replsets/0/size", "value": 3}]'
	sleep 60 # operator is chaosed for 60 sec

	local pod=$(get_operator_pod)
	local restart_count_after=$(kubectl_bin get pod ${OPERATOR_NS:+-n $OPERATOR_NS} ${pod} -ojsonpath='{.status.containerStatuses[0].restartCount}')
	if [ "$init_pod" != "$pod" ]; then
		echo "Operator pod was killed, when it should have just been restarted."
		echo "Pod name before: $init_pod , pod name after test: $pod"
		return 1
	elif [ $restart_count_before -eq $restart_count_after ]; then
		echo "Seems operator pod was not restarted when it should have been."
		echo "Pod: $pod , restarts before: $restart_count_before , restarts after test: $restart_count_after"
		return 1
	fi

	# check if Pod started
	if [ -n "$OPERATOR_NS" ]; then
		kubectl_bin config set-context --current --namespace="$OPERATOR_NS"
	fi
	wait_pod $pod
	sleep 10
	kubectl_bin config set-context --current --namespace="$namespace"

	# check scale down
	wait_for_delete pod/$cluster-3
	wait_for_running "$cluster" 3
	wait_cluster_consistency "${cluster/-rs0/}" 3
}

kill_pod() {
	local init_pod=$(get_operator_pod)

	yq eval '
		.metadata.name = "chaos-operator-pod-kill" |
		del(.spec.selector.pods.test-namespace) |
		.spec.selector.pods.'$test_namespace'[0] = "'$init_pod'"' $conf_dir/chaos-pod-kill.yml \
		| kubectl apply --namespace $test_namespace -f -
	sleep 10

	if [ "$init_pod" == "$(get_operator_pod)" ]; then
		echo "operator pod was not killed! something went wrong."
		return 1
	fi

	desc 'check if operator works fine: scale up from 3 to 5'
	kubectl_bin patch psmdb ${cluster%%-rs0} \
		--type='json' \
		-p='[{"op": "replace", "path": "/spec/replsets/0/size", "value": 5}]'
	sleep 10

	# check scale up
	wait_for_running "$cluster" 5
	wait_cluster_consistency "${cluster/-rs0/}" 5
}

network_loss() {
	local init_pod=$(get_operator_pod)

	yq eval '
		.metadata.name = "chaos-operator-network" |
		del(.spec.selector.pods.test-namespace) |
		.spec.selector.pods.'$test_namespace'[0] = "'$init_pod'"' $conf_dir/chaos-network-loss.yml \
		| kubectl apply --namespace $test_namespace -f -
	sleep 10

	desc 'check if operator works fine: scale up from 3 to 5'
	kubectl_bin patch psmdb ${cluster%%-rs0} \
		--type='json' \
		-p='[{"op": "replace", "path": "/spec/replsets/0/size", "value": 5}]'
	sleep 10

	# check scale up
	wait_for_running "$cluster" 5
	wait_cluster_consistency "${cluster/-rs0/}" 5
}

main() {
	create_infra $namespace
	test_namespace=$namespace
	if [ -n "$OPERATOR_NS" ]; then
		kubectl_bin patch clusterrole percona-server-mongodb-operator --type=json -p '[{"op":"remove","path":"/rules/1"}]'
		test_namespace=$OPERATOR_NS
	fi
	deploy_chaos_mesh $test_namespace

	setup_cluster

	desc 'kill operator'
	kill_pod

	desc 'fail operator pod for 60s'
	fail_pod

	desc 'emulate bad network for 60s'
	network_loss

	destroy_chaos_mesh
	destroy $namespace

	desc 'test passed'
}

main
