#!/bin/bash

set -o errexit
set -o xtrace

test_dir=$(realpath "$(dirname "$0")")
. "${test_dir}/../functions"
set_debug

check_balancer() {
	local expected=$1 # should be "full" (running balancer) or "off" (disabled balancer)

	local balancer_running
	balancer_running=$(run_mongos 'db.adminCommand({balancerStatus: 1}).mode' "clusterAdmin:clusterAdmin123456@$cluster-mongos.$namespace" \
		| grep -E -v "Percona Server for MongoDB|connecting to:|Implicit session:|versions do not match|Error saving history file:|bye")

	if [[ $balancer_running != "$expected" ]]; then
		echo "Unexpected output from \"db.adminCommand({balancerStatus: 1}).mode\": $balancer_running"
		echo "Expected $expected"
		exit 1
	fi
}

check_service() {
	state=$1
    svc_name=$2
	if [ $state = "present" ]; then
		echo "check that $svc_name was created"
		local timeout=0
		until kubectl_bin get service/$svc_name -o 'jsonpath={.spec.type}' 2>&1 | grep -vq NotFound; do
			sleep 1
			timeout=$((timeout + 1))
			echo -n '.'
			if [[ ${timeout} -gt 900 ]]; then
				echo
				echo "Waiting timeout has been reached. Service $svc_name is not present. Exiting..."
				exit 1
			fi
		done
	elif [ $state = "removed" ]; then
		echo "check that $svc_name was removed"
		if [[ -z $(kubectl get service/$svc_name -o 'jsonpath={.spec.type}' 2>&1 | grep NotFound) ]] ; then
			echo "$svc_name was not removed."
			exit 1
        else
            echo "service $svc_name was removed"
		fi
	else
		echo "unknown state $state"
	fi
}

main() {
	create_infra "$namespace"

	desc 'create first PSMDB cluster'
	cluster="some-name"
	kubectl_bin apply \
		-f "$conf_dir/secrets.yml" \
		-f "$conf_dir/client.yml"

	if version_gt "1.19" && [ $EKS -ne 1 ]; then
		$sed 's/docker/runc/g' "$conf_dir/container-rc.yaml" | kubectl_bin apply -f -
	elif version_gt "1.24" && [ $EKS -eq 1 ]; then
		$sed 's/docker/runc/g' "$conf_dir/container-rc.yaml" | kubectl_bin apply -f -
	else
		kubectl_bin apply -f "$conf_dir/container-rc.yaml"
	fi

	apply_cluster "$test_dir/conf/$cluster-rs0.yml"

	desc 'check if all 3 Pods started'
	wait_for_running $cluster-rs0 3
	wait_for_running $cluster-cfg 3 "false"
	wait_for_running $cluster-mongos 3
	sleep 20
	check_balancer "full"

	desc 'disabling balancer'
	kubectl patch psmdb some-name --type=merge -p '{"spec":{"sharding":{"balancer":{"enabled":false}}}}'
	sleep 20
	check_balancer "off"

	desc 'enabling balancer'
	kubectl patch psmdb some-name --type=merge -p '{"spec":{"sharding":{"balancer":{"enabled":true}}}}'
	sleep 20
	check_balancer "full"

# Add check that servicePerPod creates 3 services for the running cluster
	desc 'enabling servicePerPod for mongos'
	kubectl patch psmdb some-name --type=merge -p '{"spec":{"sharding":{"mongos":{"expose":{"servicePerPod":true}}}}}'
	wait_for_running $cluster-mongos 3
	check_service present $cluster-mongos-0
	check_service present $cluster-mongos-1
	check_service present $cluster-mongos-2
	check_service removed $cluster-mongos

	destroy "$namespace"
}

main
