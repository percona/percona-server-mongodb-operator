#!/bin/bash

set -o errexit

test_dir=$(realpath "$(dirname "$0")")
. "${test_dir}/../functions"
set_debug

run_backup() {
	local storage=$1
	local backup_name=$2

	cat $test_dir/conf/backup.yml \
		| $sed -e "s/name:/name: ${backup_name}/" \
		| $sed -e "s/storageName:/storageName: ${storage}/" \
		| kubectl_bin apply -f -
}

run_restore() {
	local backup_name=$1

	cat $test_dir/conf/restore.yml \
		| $sed -e "s/name:/name: restore-${backup_name}/" \
		| $sed -e "s/backupName:/backupName: ${backup_name}/" \
		| kubectl_bin apply -f -
}

run_recovery_check() {
	local backup_name=$1
	local compare_suffix=${2:-"_restore"}

	wait_restore "${backup_name}" "${cluster}" "requested" "0"
	echo

	compare_kubectl "statefulset/${cluster}-rs0" ${compare_suffix}

	# we don't wait for cluster readiness here because the annotation gets removed then
	wait_restore "${backup_name}" "${cluster}" "ready" "0"
	kubectl_bin get psmdb ${cluster} -o yaml
	if [ $(kubectl_bin get psmdb ${cluster} -o yaml | yq '.metadata.annotations."percona.com/resync-pbm"') == null ]; then
		echo "psmdb/${cluster} should be annotated with percona.com/resync-pbm after a physical restore"
		exit 1
	fi
	echo
	wait_cluster_consistency ${cluster}
	compare_mongo_cmd "find" "myApp:myPass@${cluster}-rs0-0.${cluster}-rs0.${namespace}"
	compare_mongo_cmd "find" "myApp:myPass@${cluster}-rs0-1.${cluster}-rs0.${namespace}"
	compare_mongo_cmd "find" "myApp:myPass@${cluster}-rs0-2.${cluster}-rs0.${namespace}"
	echo
	set -o xtrace
}

create_infra "${namespace}"

deploy_minio
apply_s3_storage_secrets

### Case 1: Backup and restore on not sharded cluster
desc 'Testing on not sharded cluster'

echo "Creating PSMDB cluster"
cluster="some-name"
kubectl_bin apply -f "${conf_dir}/secrets.yml"
apply_cluster "${test_dir}/conf/${cluster}.yml"
kubectl_bin apply -f "${conf_dir}/client_with_tls.yml"

echo "check if all pods started"
wait_for_running ${cluster}-rs0 3
wait_cluster_consistency ${cluster}

echo 'writing test data'
run_mongo \
	'db.createUser({user:"myApp",pwd:"myPass",roles:[{db:"myApp",role:"readWrite"}]})' \
	"userAdmin:userAdmin123456@${cluster}-rs0.${namespace}"
sleep 1
run_mongo \
	'use myApp\n db.test.insert({ x: 100500 })' \
	"myApp:myPass@${cluster}-rs0.${namespace}"
sleep 5
compare_mongo_cmd "find" "myApp:myPass@${cluster}-rs0-0.${cluster}-rs0.${namespace}"
compare_mongo_cmd "find" "myApp:myPass@${cluster}-rs0-1.${cluster}-rs0.${namespace}"
compare_mongo_cmd "find" "myApp:myPass@${cluster}-rs0-2.${cluster}-rs0.${namespace}"

echo 'running backups'
backup_name_minio="backup-minio"
run_backup minio ${backup_name_minio}
if [ -z "$SKIP_BACKUPS_TO_AWS_GCP_AZURE" ]; then
	backup_name_aws="backup-aws-s3"
	backup_name_gcp="backup-gcp-cs"
	backup_name_azure="backup-azure-blob"

	run_backup aws-s3 ${backup_name_aws}
	run_backup gcp-cs ${backup_name_gcp}
	run_backup azure-blob ${backup_name_azure}

	wait_backup "${backup_name_aws}"
	wait_backup "${backup_name_gcp}"
	wait_backup "${backup_name_azure}"
fi
wait_backup "${backup_name_minio}"

if [ -z "$SKIP_BACKUPS_TO_AWS_GCP_AZURE" ]; then
	echo "drop collection"
	run_mongo 'use myApp\n db.test.drop()' "myApp:myPass@${cluster}-rs0.${namespace}"
	echo 'check backup and restore -- aws-s3'
	run_restore ${backup_name_aws}
	run_recovery_check ${backup_name_aws}

	echo "drop collection"
	run_mongo 'use myApp\n db.test.drop()' "myApp:myPass@${cluster}-rs0.${namespace}"
	echo 'check backup and restore -- gcp-cs'
	run_restore ${backup_name_gcp}
	run_recovery_check ${backup_name_gcp}

	echo "drop collection"
	run_mongo 'use myApp\n db.test.drop()' "myApp:myPass@${cluster}-rs0.${namespace}"
	echo 'check backup and restore -- azure-blob'
	run_restore ${backup_name_azure}
	run_recovery_check ${backup_name_azure}
fi

echo "drop collection"
run_mongo 'use myApp\n db.test.drop()' "myApp:myPass@${cluster}-rs0.${namespace}"
echo 'check backup and restore -- minio'
backup_dest_minio=$(get_backup_dest "${backup_name_minio}")
run_restore ${backup_name_minio}
run_recovery_check ${backup_name_minio}

destroy "$namespace"
