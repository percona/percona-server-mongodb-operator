#!/bin/bash

set -o errexit
set -o xtrace

test_dir=$(realpath $(dirname $0))
. ${test_dir}/../functions

cluster="upgrade-sharded"
CLUSTER_SIZE=3
TARGET_API="${API}"
TARGET_OPERATOR_VER="${OPERATOR_VERSION}"
TARGET_IMAGE="${IMAGE}"
TARGET_IMAGE_MONGOD="${IMAGE_MONGOD}"
TARGET_IMAGE_PMM="${IMAGE_PMM}"
TARGET_IMAGE_BACKUP="${IMAGE_BACKUP}"
if [[ ${TARGET_IMAGE_MONGOD} == *"percona-server-mongodb-operator"* ]]; then
	MONGO_VER=$(echo -n "${TARGET_IMAGE_MONGOD}" | $sed -r 's/.*([0-9].[0-9])$/\1/')
else
	MONGO_VER=$(echo -n "${TARGET_IMAGE_MONGOD}" | $sed -r 's/.*:([0-9]+\.[0-9]+).*$/\1/')
fi

INIT_OPERATOR_VER=$(curl -s https://check.percona.com/versions/v1/psmdb-operator | jq -r '.versions[].operator' | sort -V | tail -n1)
# if testing on release branch and version service is already updated with new operator images
# use the older version of operator as initial point for test
if [[ ${INIT_OPERATOR_VER} == "${TARGET_OPERATOR_VER}" ]]; then
	INIT_OPERATOR_VER=$(curl -s https://check.percona.com/versions/v1/psmdb-operator | jq -r '.versions[].operator' | sort -V | tail -n2 | head -n1)
fi
GIT_TAG="v${INIT_OPERATOR_VER}"
INIT_OPERATOR_IMAGES=$(curl -s "https://check.percona.com/versions/v1/psmdb-operator/${INIT_OPERATOR_VER}/latest?databaseVersion=${MONGO_VER}")
OPERATOR_NAME='percona-server-mongodb-operator'
API="psmdb.percona.com/v${INIT_OPERATOR_VER//./-}"
IMAGE=$(echo "${INIT_OPERATOR_IMAGES}" | jq -r '.versions[].matrix.operator[].imagePath')
# we use the starting image from the same repo so we don't need to use initImage option
if [[ "$(echo ${TARGET_IMAGE} | cut -d'/' -f1)" == "perconalab" ]]; then
	IMAGE="${IMAGE/percona\//perconalab\/}"
fi
IMAGE_MONGOD=$(echo "${INIT_OPERATOR_IMAGES}" | jq -r '.versions[].matrix.mongod[].imagePath')
IMAGE_PMM=$(echo "${INIT_OPERATOR_IMAGES}" | jq -r '.versions[].matrix.pmm[].imagePath')
IMAGE_BACKUP=$(echo "${INIT_OPERATOR_IMAGES}" | jq -r '.versions[].matrix.backup[].imagePath')

if [[ ${TARGET_API} == "${API}" ]]; then
	echo "API and TARGET_API variables are the same: ${API}! Something is wrong!"
	exit 1
fi

function compare_generation() {
	local generation="$1"
	local resource="${2:-statefulset}"
	local name="$3"
	local current_generation

	current_generation=$(kubectl_bin get "${resource}" "${name}" -o jsonpath='{.metadata.generation}')
	if [[ ${generation} != "${current_generation}" ]]; then
		echo "Generation for resource type ${resource} with name ${name} is: ${current_generation}, but should be: ${generation}!"
		exit 1
	fi
}

function wait_cluster_consistency() {
	local retry=0
	until [[ "$(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.status.state}')" == "ready" &&
	"$(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.status.replsets.rs0.ready}')" == "${CLUSTER_SIZE}" &&
	"$(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.status.replsets.cfg.ready}')" == "${CLUSTER_SIZE}" ]]; do
		let retry+=1
		if [ $retry -ge 32 ]; then
			echo max retry count $retry reached. something went wrong with operator or kubernetes cluster
			exit 1
		fi
		echo 'waiting for cluster readyness'
		sleep 20
	done
}

function check_applied_images() {
	local updated_image="$1"

	case "${updated_image}" in
		"operator")
			if [[ ${TARGET_IMAGE} == $(kubectl_bin get pod --selector=name="${OPERATOR_NAME}" -o jsonpath='{.items[*].spec.containers[?(@.name == "'"${OPERATOR_NAME}"'")].image}') &&
			${IMAGE_BACKUP} == $(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.spec.backup.image}') &&
			${IMAGE_PMM} == $(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.spec.pmm.image}') &&
			${IMAGE_MONGOD} == $(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.spec.image}') ]]; then
				: Operator image has been updated correctly
			else
				echo 'Operator image has not been updated'
				exit 1
			fi
			;;
		"all")
			if [[ ${TARGET_IMAGE} == $(kubectl_bin get pod --selector=name="${OPERATOR_NAME}" -o jsonpath='{.items[*].spec.containers[?(@.name == "'"${OPERATOR_NAME}"'")].image}') &&
			${TARGET_IMAGE_BACKUP} == $(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.spec.backup.image}') &&
			${TARGET_IMAGE_PMM} == $(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.spec.pmm.image}') &&
			${TARGET_IMAGE_MONGOD} == $(kubectl_bin get psmdb "${cluster}" -o jsonpath='{.spec.image}') ]]; then
				: Cluster images have been updated correctly
			else
				echo 'Cluster images have not been updated'
				exit 1
			fi
			;;
	esac
}

function prepare_cr_yaml() {
	local cr_yaml="$1"

	# spinup function expects images to have suffix like "-backup"
	# to replace them with images from environment variables
	curl -s "https://raw.githubusercontent.com/percona/percona-server-mongodb-operator/${GIT_TAG}/deploy/cr.yaml" \
		| yq eval '
			.metadata.name = "'${cluster}'" |
			.spec.upgradeOptions.apply = "disabled" |
			.spec.replsets[].size = '${CLUSTER_SIZE}' |
			.spec.replsets[].arbiter.enabled = "false" |
			.spec.backup.enabled = "true" |
			.spec.backup.tasks = "[]" |
			.spec.backup.pitr.enabled = "false" |
			.spec.backup.storages.minio.type = "s3" |
			.spec.backup.storages.minio.s3.credentialsSecret = "minio-secret" |
			.spec.backup.storages.minio.s3.region = "us-east-1" |
			.spec.backup.storages.minio.s3.bucket = "operator-testing" |
			.spec.backup.storages.minio.s3.endpointUrl = "http://minio-service:9000/" |
			.spec.backup.storages.minio.s3.insecureSkipTLSVerify = "false" |
			.spec.sharding.enabled = "true" |
			.spec.sharding.configsvrReplSet.size = "${CLUSTER_SIZE}" |
			.spec.sharding.mongos.size = "${CLUSTER_SIZE}" |
			.spec.image = "" |
			.spec.backup.image = "-backup" |
			.spec.pmm.image = "-pmm"' >"${cr_yaml}"
}

function check_upgrade_order() {
	local pod_type=$1
	local cluster_size=$2
	local upgrade_order=$3

	local start=$((upgrade_order * cluster_size - cluster_size + 1))
	local end=$((upgrade_order * cluster_size))
	local nr=$(kubectl_bin get pod --sort-by=.status.startTime | grep -vE '^NAME|client|operator|minio-service' | sed -n "${start},${end}p" | grep -c "\-${pod_type}\-")

	if [[ ${nr} -ne ${cluster_size} ]]; then
		echo "${pod_type} was not upgraded ${upgrade_order}!"
		kubectl_bin get pod --sort-by=.status.startTime | grep -vE 'client|operator|minio-service'
		exit 1
	else
		echo "${pod_type} was upgraded ${upgrade_order}!"
	fi
}

function main() {
	rbac="rbac"
	if [ -n "$OPERATOR_NS" ]; then
		rbac="cw-rbac"
	fi
	deploy_cert_manager
	create_infra_gh "${namespace}" "${GIT_TAG}"
	apply_s3_storage_secrets
	deploy_minio

	curl -s "https://raw.githubusercontent.com/percona/percona-server-mongodb-operator/${GIT_TAG}/deploy/secrets.yaml" >"${tmp_dir}/secrets.yaml"
	kubectl_bin apply -f "${conf_dir}/client.yml" \
		-f "${tmp_dir}/secrets.yaml"

	local cr_yaml="${tmp_dir}/cr_${GIT_TAG}.yaml"
	prepare_cr_yaml "${cr_yaml}"
	apply_cluster "${cr_yaml}"
	wait_for_running "${cluster}-rs0" "${CLUSTER_SIZE}" "false"
	wait_for_running "${cluster}-cfg" "${CLUSTER_SIZE}" "false"
	wait_cluster_consistency "${cluster}" "${CLUSTER_SIZE}"
	run_mongos 'db.createUser({user: "myApp", pwd: "myPass", roles: [{ db: "myApp", role: "readWrite" }]})' \
		"userAdmin:userAdmin123456@${cluster}-mongos.${namespace}"

	run_mongos 'use myApp\n db.test.insert({ x: 100500 })' "myApp:myPass@${cluster}-mongos.${namespace}"

	compare_generation "1" "statefulset" "${cluster}-rs0"
	compare_generation "1" "statefulset" "${cluster}-cfg"
	compare_generation "1" "psmdb" "${cluster}"

	# create backup
	backup_name_minio="backup-minio"
	wait_backup_agent $cluster-rs0-0
	wait_backup_agent $cluster-rs0-1
	wait_backup_agent $cluster-rs0-2
	wait_backup_agent $cluster-cfg-0
	wait_backup_agent $cluster-cfg-1
	wait_backup_agent $cluster-cfg-2
	run_backup minio
	wait_backup "$backup_name_minio"

	desc 'upgrade operator'
	kubectl_bin apply --server-side --force-conflicts -f "${src_dir}/deploy/crd.yaml"
	kubectl_bin apply -f "${src_dir}/deploy/${rbac}.yaml" ${OPERATOR_NS:+-n $OPERATOR_NS}
	kubectl_bin patch deployment ${OPERATOR_NS:+-n $OPERATOR_NS} "${OPERATOR_NAME}" \
		-p'{"spec":{"template":{"spec":{"containers":[{"name":"'"${OPERATOR_NAME}"'","image":"'"${TARGET_IMAGE}"'"}]}}}}'
	kubectl_bin rollout status deployment/"${OPERATOR_NAME}" ${OPERATOR_NS:+-n $OPERATOR_NS}

	desc 'wait for operator upgrade'
	until [[ $(kubectl_bin get pods ${OPERATOR_NS:+-n $OPERATOR_NS} --selector=name="${OPERATOR_NAME}" \
		-o custom-columns='NAME:.metadata.name,IMAGE:.spec.containers[0].image' \
		| grep -vc 'NAME' | awk '{print $1}') -eq 1 ]]; do
		sleep 5
	done
	sleep 10

	desc 'check images and generation after operator upgrade'
	wait_for_running "${cluster}-rs0" "${CLUSTER_SIZE}" "false"
	wait_for_running "${cluster}-cfg" "${CLUSTER_SIZE}" "false"
	wait_cluster_consistency "${cluster}" "${CLUSTER_SIZE}"
	check_applied_images "operator"
	compare_generation "1" "statefulset" "${cluster}-rs0"
	compare_generation "1" "statefulset" "${cluster}-cfg"
	compare_generation "1" "statefulset" "${cluster}-mongos"
	compare_generation "1" "psmdb" "${cluster}"

	desc 'patch psmdb images and upgrade'
	kubectl_bin patch psmdb "${cluster}" --type=merge --patch '{
        "spec": {
            "crVersion": "'"${TARGET_OPERATOR_VER}"'",
            "image": "'"${TARGET_IMAGE_MONGOD}"'",
            "pmm": { "image": "'"${TARGET_IMAGE_PMM}"'" },
            "backup": { "image": "'"${TARGET_IMAGE_BACKUP}"'" }
        }}'
	sleep 10

	desc 'check cluster after full upgrade'
	wait_for_running "${cluster}-rs0" "${CLUSTER_SIZE}" "false"
	wait_for_running "${cluster}-cfg" "${CLUSTER_SIZE}" "false"
	wait_cluster_consistency "${cluster}" "${CLUSTER_SIZE}"
	simple_data_check "${cluster}" "${CLUSTER_SIZE}" 1 "-mongos"
	check_applied_images "all"
	compare_generation "2" "statefulset" "${cluster}-rs0"
	compare_generation "2" "statefulset" "${cluster}-cfg"
	compare_generation "2" "statefulset" "${cluster}-mongos"
	compare_generation "2" "psmdb" "${cluster}"

	desc 'check if upgrade order is cfg, rs0, mongos'
	sleep 60 # this is needed because mongos has no status
	check_upgrade_order "cfg" "${CLUSTER_SIZE}" "1"
	check_upgrade_order "rs0" "${CLUSTER_SIZE}" "2"
	check_upgrade_order "mongos" "${CLUSTER_SIZE}" "3"

	desc 'drop collection and do restore with new version'
	run_mongos 'use myApp\n db.test.drop()' "myApp:myPass@${cluster}-mongos.${namespace}"

	backup_dest_minio=$(get_backup_dest "$backup_name_minio")
	retry 3 5 kubectl_bin run -i --rm aws-cli --image=perconalab/awscli --restart=Never -- \
		/usr/bin/env AWS_ACCESS_KEY_ID=some-access-key AWS_SECRET_ACCESS_KEY=some-secret-key AWS_DEFAULT_REGION=us-east-1 \
		/usr/bin/aws --endpoint-url http://minio-service:9000 s3 ls "s3://operator-testing/${backup_dest_minio}" \
		| grep "${backup_dest_minio}_rs0.dump.gz"
	run_restore $backup_name_minio 3 1 "-mongos"
	wait_restore $backup_name_minio 3 1 "-mongos"
	simple_data_check "${cluster}" "${CLUSTER_SIZE}" 1 "-mongos"

	desc 'cleanup'
	destroy "${namespace}"
}

main
